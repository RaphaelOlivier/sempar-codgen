iter 0: train loss/word=172.4686, ppl=798298467630920379592347715357116909811262281847520680601084481962910941184.0000, time=20.54s
iter 1: train loss/word=75.7108, ppl=759940321274768823226496469434368.0000, time=21.05s
iter 2: train loss/word=59.4579, ppl=66412311504700017177788416.0000, time=21.16s
iter 3: train loss/word=51.6810, ppl=27846654248576085917696.0000, time=20.84s
iter 4: train loss/word=46.6955, ppl=190362147021407715328.0000, time=22.38s
iter 5: train loss/word=43.0832, ppl=5137772515293831168.0000, time=21.19s
iter 6: train loss/word=40.0077, ppl=237214930596787808.0000, time=23.19s
iter 7: train loss/word=37.2013, ppl=14332447316857950.0000, time=22.45s
iter 8: train loss/word=34.2278, ppl=732755227790588.1250, time=20.94s
iter 9: train loss/word=32.7293, ppl=163736045718703.6875, time=26.41s
