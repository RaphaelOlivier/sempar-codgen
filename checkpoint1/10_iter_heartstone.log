iter 0: train loss/word=176.4043, ppl=40870908610886355049886903347412599823074491764960314424079081592095640649728.0000, time=20.71s
iter 1: train loss/word=75.5824, ppl=668369236804744017084591825223680.0000, time=21.26s
iter 2: train loss/word=58.6810, ppl=30537489325604332875284480.0000, time=21.75s
iter 3: train loss/word=51.1626, ppl=16581765781893511380992.0000, time=22.69s
iter 4: train loss/word=46.2350, ppl=120120092850125832192.0000, time=22.03s
iter 5: train loss/word=42.5422, ppl=2991164562126637056.0000, time=24.90s
iter 6: train loss/word=39.5727, ppl=153536389722332960.0000, time=20.86s
iter 7: train loss/word=36.9333, ppl=10963324915286230.0000, time=22.49s
iter 8: train loss/word=34.0147, ppl=592101194668489.1250, time=21.88s
iter 9: train loss/word=32.5137, ppl=131987215336241.0625, time=21.65s
